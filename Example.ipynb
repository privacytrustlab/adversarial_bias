{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from attacks import *\n",
    "from train import *\n",
    "from tempeh.configurations import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we go through some attacks presented in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation  \n",
    "\n",
    "We get the COMPAS data from tempeh  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_dataset = datasets['compas']()\n",
    "X_train, X_test = compas_dataset.get_X(format=pd.DataFrame)\n",
    "y_train, y_test = compas_dataset.get_y(format=pd.Series)\n",
    "sensitive_features_train, sensitive_features_test = compas_dataset.get_sensitive_features('race', format=pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.to_numpy()\n",
    "x_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "g_train = sensitive_features_train.to_numpy()\n",
    "g_test = sensitive_features_test.to_numpy()\n",
    "_, g_train = np.unique(g_train, return_inverse=True)\n",
    "_, g_test = np.unique(g_test, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((x_train,x_test),axis=0)\n",
    "Y = np.append(y_train,y_test)\n",
    "G = np.append(g_train,g_test)\n",
    "\n",
    "# G is included in X\n",
    "X = np.concatenate([X, G.reshape(-1,1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use SVM + rbf kernel to generate data. Keep 60% as clean data and 40% left out as hard examples  \n",
    "$|D_c|:|D_{test}|:|D_k| = 4:1:1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_dataset(X, Y, G, 'rbf',\n",
    "                        clean_ratio=0.6, attacker_split=1.0/6, \n",
    "                        test_split=0.2, random_seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN = data['x_train']\n",
    "Y_TRAIN = data['y_train']\n",
    "G_TRAIN = data['g_train']\n",
    "\n",
    "X_TEST = data['x_test']\n",
    "Y_TEST = data['y_test']\n",
    "G_TEST = data['g_test']\n",
    "\n",
    "X_ATTACK = data['x_attacker']\n",
    "Y_ATTACK = data['y_attacker']\n",
    "G_ATTACK = data['g_attacker']\n",
    "\n",
    "# hard examples\n",
    "X_NOISE = data['x_noise']\n",
    "Y_NOISE = data['y_noise']\n",
    "G_NOISE = data['g_noise']\n",
    "\n",
    "# attacker set is augmented by hard examples\n",
    "\n",
    "X_ATTACK = np.concatenate([X_ATTACK, X_NOISE])\n",
    "Y_ATTACK = np.append(Y_ATTACK, Y_NOISE)\n",
    "G_ATTACK = np.append(G_ATTACK, G_NOISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain = {\n",
    "    'x_train': X_TRAIN,\n",
    "    'y_train': Y_TRAIN,\n",
    "    'g_train': G_TRAIN\n",
    "}\n",
    "attacker_set = {\n",
    "    'x_train': X_ATTACK,\n",
    "    'y_train': Y_ATTACK,\n",
    "    'g_train': G_ATTACK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1 #fraction of poisoning data\n",
    "base_model = LogisticRegression(max_iter=2000, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sampling attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_POI, Y_POI, G_POI = uniform_sampling(datatrain, attacker_set, epsilon, flip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained_model = train_unconstraind_model(base_model, X_POI, Y_POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9337121212121212\n",
      "Fairness gap: 0.2670937195376689\n"
     ]
    }
   ],
   "source": [
    "pred_unconstrained = unconstrained_model(X_TEST)\n",
    "print(\"Accuracy:\", accuracy(Y_TEST, pred_unconstrained))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_unconstrained, Y_TEST)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair model by Reductions  \n",
    "We use fairness gap $\\delta=0.01$ through out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = 0.01\n",
    "fair_model = train_fair_model_reduction(base_model, X_POI, Y_POI, G_POI, EqualizedOdds(), gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9278107539276724\n",
      "Fairness gap: 0.0362830839917514\n"
     ]
    }
   ],
   "source": [
    "pred_fair = np.array(fair_model(X_TEST))\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_fair))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_fair, Y_TEST))) #fairness gap measure on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair model by Post processing  \n",
    "For post processing, exact fairness is satisfied on training data ($\\delta=0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_model_PP = train_fair_model_post_processing(base_model, X_POI, Y_POI.astype(int), G_POI.astype(int), 'equalized_odds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8346078826582257\n",
      "Fairness gap: 0.04908101670507625\n"
     ]
    }
   ],
   "source": [
    "pred_fair_PP = np.array(fair_model_PP(X_TEST, G_TEST.astype(int)))\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_fair_PP))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_fair_PP, Y_TEST)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1  \n",
    "For algorithm 1 we use $L = \\lambda/\\epsilon = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_POI, Y_POI, G_POI = algorithm1(datatrain, attacker_set, epsilon, L=1, num_iters=2000, r=1, lr=0.001, flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained_model = train_unconstraind_model(base_model, X_POI, Y_POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8863636363636364\n",
      "Fairness gap: 0.4091352179362206\n"
     ]
    }
   ],
   "source": [
    "pred_unconstrained = unconstrained_model(X_TEST)\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_unconstrained))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_unconstrained, Y_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_model = train_fair_model_reduction(base_model, X_POI, Y_POI, G_POI, EqualizedOdds(), gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7798028037736952\n",
      "Fairness gap: 0.06903169994753355\n"
     ]
    }
   ],
   "source": [
    "pred_fair = np.array(fair_model(X_TEST))\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_fair))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_fair, Y_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_model_PP = train_fair_model_post_processing(base_model, X_POI, Y_POI.astype(int), G_POI.astype(int), 'equalized_odds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7266146685354307\n",
      "Fairness gap: 0.10639372848892825\n"
     ]
    }
   ],
   "source": [
    "pred_fair_PP = np.array(fair_model_PP(X_TEST, G_TEST.astype(int)))\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_fair_PP))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_fair_PP, Y_TEST)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 2  \n",
    "For algorithm 2 we use $L = \\lambda/\\epsilon = 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 3us/step - loss: 1.6531 - acc: 0.5715\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 3us/step - loss: 0.6836 - acc: 0.7884\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 3us/step - loss: 0.6162 - acc: 0.8935\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 6us/step - loss: 0.5743 - acc: 0.9129\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 3us/step - loss: 0.5710 - acc: 0.9100\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 4us/step - loss: 0.5388 - acc: 0.8920\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 3us/step - loss: 0.5861 - acc: 0.8930\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 2us/step - loss: 0.5306 - acc: 0.8878\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 4us/step - loss: 0.5566 - acc: 0.8911\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 0s 2us/step - loss: 0.5215 - acc: 0.8958\n"
     ]
    }
   ],
   "source": [
    "X_POI, Y_POI, G_POI = algorithm2(datatrain, attacker_set, epsilon, L=100, num_iters=1000, flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained_model = train_unconstraind_model(base_model, X_POI, Y_POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9166666666666666\n",
      "Fairness gap: 0.125\n"
     ]
    }
   ],
   "source": [
    "pred_unconstrained = unconstrained_model(X_TEST)\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_unconstrained))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_unconstrained, Y_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_model = train_fair_model_reduction(base_model, X_POI, Y_POI, G_POI, EqualizedOdds(), gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7473789269733544\n",
      "Fairness gap: 0.3348137543433376\n"
     ]
    }
   ],
   "source": [
    "pred_fair = np.array(fair_model(X_TEST))\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_fair))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_fair, Y_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_model_PP = train_fair_model_post_processing(base_model, X_POI, Y_POI.astype(int), G_POI.astype(int), 'equalized_odds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7057768399396952\n",
      "Fairness gap: 0.5559770754491261\n"
     ]
    }
   ],
   "source": [
    "pred_fair_PP = np.array(fair_model_PP(X_TEST, G_TEST.astype(int)))\n",
    "print(\"Accuracy:\",  accuracy(Y_TEST, pred_fair_PP))\n",
    "print(\"Fairness gap:\", max(EO(G_TEST, pred_fair_PP, Y_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
